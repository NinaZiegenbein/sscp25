{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244138ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import monai\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "from monai.bundle import load_bundle_config\n",
    "from huggingface_hub import hf_hub_download\n",
    "import cv2 #The import-call for cv2 is \"pip install opencv-python\" (not cv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49ee1b5",
   "metadata": {},
   "source": [
    "Must know:\n",
    "- ID 207: Add a folder named \"sax\" in cine and move all subfolders (with the weird names) in there for consistency\n",
    "\n",
    "Good to know:\n",
    "- All missing IDs have a \"-\" in column \"Folders (y/n)\". So when you find out folder-order and first and last for the missing ones, change that to \"y\" and run the code again. \n",
    "- We should ask about 187 (no sax folder), for now it also has a \"-\" and is ignored.\n",
    "- Otherwise scroll down for the function calls. I structured it this way so it's easy to make into a .py file, but notebook is easier for debugging etc.\n",
    "- Check out the TODO tag below about the affine to convert it into Nifti format and wether that is necessary for input into Giulia's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Extracts sliceloc and triggertime values from a filename.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): Filename containing 'sliceloc_{val}_triggertime_{val}'.\n",
    "\n",
    "    Returns:\n",
    "        tuple[float | None, float | None]: Parsed sliceloc and triggertime as floats, or (None, None) if not found.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"sliceloc_([-\\d.]+)_triggertime_([-\\d.]+)\", filename)\n",
    "    if match:\n",
    "        return float(match.group(1)), float(match.group(2))\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773df45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_files_n(df, base_path):\n",
    "    \"\"\"\n",
    "    Selects one relevant file per slice location for each patient based on ED frame and apex–base range.\n",
    "\n",
    "    For each patient, searches {base_path}/{ID}/cine/sax/ (recursively) for files named \n",
    "    like '...sliceloc_{val}_triggertime_{val}'. Keeps only slices within the apex–base \n",
    "    range and selects the earliest (ED Slice == 0) or latest frame per slice.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): df_y (see above); DataFrame of \"ED_slices_and_timepoints.csv\", without series-substructure\n",
    "        base_path (str): Root path containing the patient folders.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list[str]]: Mapping from patient ID to selected file paths.\n",
    "    \"\"\"\n",
    "    patient_files = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        pid = str(row[\"ID\"]).strip()\n",
    "        try:\n",
    "            ed_slice = int(row[\"ED frame\"])\n",
    "            apex = float(row[\"apex\"])\n",
    "            base = float(row[\"base\"])\n",
    "        except (ValueError, TypeError):\n",
    "            # Skip malformed rows\n",
    "            continue\n",
    "\n",
    "        folder = os.path.join(base_path, pid, \"cine\", \"sax\")\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"Warning: folder not found for patient {pid}\")\n",
    "            continue\n",
    "\n",
    "        files = [p for p in Path(folder).rglob(\"*\") if p.is_file()]\n",
    "        parsed = []\n",
    "\n",
    "        # Parse filenames\n",
    "        for f in files:\n",
    "            fname = f.name\n",
    "            sliceloc, triggertime = parse_filename(fname)\n",
    "            if sliceloc is not None and triggertime is not None:\n",
    "                parsed.append((f, sliceloc, triggertime))\n",
    "\n",
    "        if not parsed:\n",
    "            print(f\"Warning: no valid files for patient {pid}\")\n",
    "            continue\n",
    "\n",
    "        # Group by sliceloc → list of triggertimes\n",
    "        sliceloc_map = defaultdict(list)\n",
    "        for f, sliceloc, triggertime in parsed:\n",
    "            sliceloc_map[sliceloc].append((f, triggertime))\n",
    "\n",
    "        lower, upper = sorted([apex, base])\n",
    "        selected = []\n",
    "\n",
    "        for sliceloc, items in sliceloc_map.items():\n",
    "            if lower <= sliceloc <= upper:\n",
    "                times = [tt for _, tt in items]\n",
    "                if ed_slice == 0:\n",
    "                    target_tt = min(times)\n",
    "                else:\n",
    "                    target_tt = max(times)\n",
    "\n",
    "                # Add the file with this sliceloc + target triggertime\n",
    "                for f, tt in items:\n",
    "                    if tt == target_tt:\n",
    "                        selected.append(str(f))\n",
    "                        break  # Only one per sliceloc\n",
    "\n",
    "        patient_files[pid] = selected\n",
    "\n",
    "    return patient_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6942e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_files_y(df, base_path):\n",
    "    \"\"\"\n",
    "    Selects one relevant file per folder-defined slice for each patient using ED frame.\n",
    "\n",
    "    For each patient, looks inside {base_path}/{ID}/cine/sax/series_{folder}/ for files.\n",
    "    The slice locations are inferred from subfolder names (e.g. 'series_25').\n",
    "    The column 'folder order' lists all available series (in order),\n",
    "    while 'apex' and 'base' define the first and last folder to include.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with columns 'ID', 'ED Slice', 'apex', 'base', and 'folder order'.\n",
    "        base_path (str): Root path containing the patient folders.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list[str]]: Mapping from patient ID to selected file paths.\n",
    "    \"\"\"\n",
    "\n",
    "    patient_files = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        pid = str(row[\"ID\"]).strip()\n",
    "        try:\n",
    "            ed_slice = int(row[\"ED frame\"])\n",
    "            apex = int(row[\"apex\"])\n",
    "            base = int(row[\"base\"])\n",
    "            folder_order = str(row[\"folder order\"]).strip()\n",
    "        except (ValueError, TypeError):\n",
    "            print(f\"Could not extract values for ID {pid}\")\n",
    "            continue\n",
    "\n",
    "        if not folder_order or folder_order.lower() == \"nan\":\n",
    "            continue\n",
    "\n",
    "        sax_root = os.path.join(base_path, pid, \"cine\", \"sax\")\n",
    "        if not os.path.isdir(sax_root):\n",
    "            print(f\"Warning: folder not found for patient {pid}\")\n",
    "            continue\n",
    "\n",
    "        # Get ordered folder list (as ints)\n",
    "        order = [int(x) for x in folder_order.split(\"-\") if x.isdigit()]\n",
    "        lower, upper = sorted([apex, base])\n",
    "        lower_idx, upper_idx = order.index(lower), order.index(upper)\n",
    "        selected_series = order[lower_idx:upper_idx+1]\n",
    "\n",
    "        selected = []\n",
    "\n",
    "        for sliceloc in selected_series:\n",
    "            series_path = os.path.join(sax_root, f\"series_{sliceloc}\")\n",
    "            if not os.path.isdir(series_path):\n",
    "                print(f\"Warning: missing folder series_{sliceloc} for patient {pid}\")\n",
    "                continue\n",
    "\n",
    "            files = glob.glob(os.path.join(series_path, \"*\"))\n",
    "            triggertimes = []\n",
    "\n",
    "            for f in files:\n",
    "                _, tt = parse_filename(os.path.basename(f))\n",
    "                if tt is not None:\n",
    "                    triggertimes.append((f, tt))\n",
    "\n",
    "            if not triggertimes:\n",
    "                continue\n",
    "\n",
    "            if ed_slice == 0:\n",
    "                chosen_file = min(triggertimes, key=lambda x: x[1])[0]\n",
    "            else:\n",
    "                chosen_file = max(triggertimes, key=lambda x: x[1])[0]\n",
    "\n",
    "            selected.append(chosen_file)\n",
    "\n",
    "        patient_files[pid] = selected\n",
    "\n",
    "    return patient_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_segmentation(files_dicts, output_root, save_as_stack: bool):\n",
    "    \"\"\"\n",
    "    Runs MONAI ventricular segmentation on all DICOM files provided in files_dicts.\n",
    "\n",
    "    Parameters:\n",
    "        files_dicts (list[dict]): List of dicts (e.g., [files_n, files_y]) with {pid: [file_paths]}.\n",
    "        output_root (str): Root folder where output NIfTI files will be saved.\n",
    "    \"\"\"\n",
    "    # Load MONAI network config & weights\n",
    "    parser = load_bundle_config(\"MONAI\", \"train.json\")\n",
    "    net = parser.get_parsed_content(\"network_def\")\n",
    "\n",
    "    model_path = hf_hub_download(\n",
    "        repo_id=\"MONAI/ventricular_short_axis_3label\",\n",
    "        filename=\"models/model.pt\"\n",
    "    )\n",
    "    net.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    net.eval()\n",
    "\n",
    "    target_shape = (256, 256) \n",
    "\n",
    "    for files_dict in files_dicts:\n",
    "        for pid, paths in files_dict.items():\n",
    "            num_slices = len(paths)\n",
    "            img_stack = []\n",
    "            seg_stack = []\n",
    "            for idx, path in enumerate(paths):\n",
    "                # Read and preprocess DICOM\n",
    "                ds = pydicom.dcmread(path)\n",
    "                img = ds.pixel_array.astype(np.float32)\n",
    "\n",
    "                #print(f\"Original image shape: {img.shape}, ndim: {img.ndim}\")\n",
    "\n",
    "                # Resample width and height to fixed size (256, 256) \n",
    "                im_resized = cv2.resize(img, (target_shape[1], target_shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # Adjust contrast\n",
    "                # im_resized = cv2.convertScaleAbs(im_resized, alpha=1.465, beta=0.0) # Used alpha-value provided by Giulia (this adjusts contrast)\n",
    "\n",
    "                #print(f\"Resized image shape: {im_resized.shape}\")\n",
    "\n",
    "                # Normalize and add batch & channel dims\n",
    "                normed_im = im_resized / im_resized.max()\n",
    "                input_tensor = torch.from_numpy(normed_im).float()[None, None, :, :]\n",
    "\n",
    "                # Predict\n",
    "                with torch.no_grad():\n",
    "                    pred = net(input_tensor)\n",
    "                    pred = torch.softmax(pred[0], dim=0)\n",
    "                    seg = torch.argmax(pred, dim=0).numpy()\n",
    "\n",
    "                if save_as_stack:\n",
    "                    img_stack.append(normed_im)\n",
    "                    seg_stack.append(seg)\n",
    "                else:\n",
    "                    # Save\n",
    "                    pid_folder = os.path.join(output_root, str(pid))\n",
    "                    os.makedirs(pid_folder, exist_ok=True)\n",
    "\n",
    "                    affine = np.eye(4)  # identity affine \n",
    "                    #TODO: Look into this. This is an identity affine to map from numpy array to nifti file format, but we should probably\n",
    "                    # use the one from the DICOM - or does this not matter for input into Giulia's code?\n",
    "\n",
    "                    nib.save(nib.Nifti1Image(normed_im, affine), os.path.join(pid_folder, f\"{idx}_img.nii.gz\"))\n",
    "                    nib.save(nib.Nifti1Image(seg.astype(np.uint8), affine), os.path.join(pid_folder, f\"{idx}_seg.nii.gz\"))\n",
    "\n",
    "                    print(f\"Saved {pid} slice {idx}\")\n",
    "        \n",
    "            if save_as_stack and num_slices > 0: # NOTE: The order of the slices for patients with no folder structure is not necessarily correct.\n",
    "                \n",
    "                # Save the entire stack as a single NIfTI file\n",
    "                pid_folder = os.path.join(output_root, str(pid))\n",
    "                os.makedirs(pid_folder, exist_ok=True)\n",
    "\n",
    "                img_stack = np.stack(img_stack, axis=-1)\n",
    "                seg_stack = np.stack(seg_stack, axis=-1)\n",
    "\n",
    "                affine = np.eye(4)  # identity affine for the stack\n",
    "\n",
    "                nib.save(nib.Nifti1Image(img_stack, affine), os.path.join(pid_folder, \"img_stack.nii.gz\"))\n",
    "                nib.save(nib.Nifti1Image(seg_stack.astype(np.uint8), affine), os.path.join(pid_folder, \"seg_stack.nii.gz\"))\n",
    "\n",
    "                print(f\"Saved {pid} image and segmentation stacks\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "73109e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 15 slice 0\n",
      "Saved 15 slice 1\n",
      "Saved 15 slice 2\n",
      "Saved 15 slice 3\n",
      "Saved 15 slice 4\n",
      "Saved 15 slice 5\n",
      "Saved 15 slice 6\n",
      "Saved 15 slice 7\n",
      "Saved 114 slice 0\n",
      "Saved 114 slice 1\n",
      "Saved 114 slice 2\n",
      "Saved 114 slice 3\n",
      "Saved 114 slice 4\n",
      "Saved 114 slice 5\n",
      "Saved 114 slice 6\n",
      "Saved 114 slice 7\n",
      "Saved 114 slice 8\n",
      "Saved 114 slice 9\n",
      "Saved 114 slice 10\n",
      "Saved 114 slice 11\n",
      "Saved 126 slice 0\n",
      "Saved 126 slice 1\n",
      "Saved 126 slice 2\n",
      "Saved 126 slice 3\n",
      "Saved 126 slice 4\n",
      "Saved 126 slice 5\n",
      "Saved 126 slice 6\n",
      "Saved 126 slice 7\n",
      "Saved 126 slice 8\n",
      "Saved 126 slice 9\n",
      "Saved 130 slice 0\n",
      "Saved 130 slice 1\n",
      "Saved 130 slice 2\n",
      "Saved 130 slice 3\n",
      "Saved 130 slice 4\n",
      "Saved 130 slice 5\n",
      "Saved 130 slice 6\n",
      "Saved 130 slice 7\n",
      "Saved 130 slice 8\n",
      "Saved 130 slice 9\n",
      "Saved 130 slice 10\n",
      "Saved 130 slice 11\n",
      "Saved 138 slice 0\n",
      "Saved 138 slice 1\n",
      "Saved 138 slice 2\n",
      "Saved 138 slice 3\n",
      "Saved 138 slice 4\n",
      "Saved 138 slice 5\n",
      "Saved 138 slice 6\n",
      "Saved 163 slice 0\n",
      "Saved 163 slice 1\n",
      "Saved 163 slice 2\n",
      "Saved 163 slice 3\n",
      "Saved 163 slice 4\n",
      "Saved 163 slice 5\n",
      "Saved 163 slice 6\n",
      "Saved 163 slice 7\n",
      "Saved 163 slice 8\n",
      "Saved 207 slice 0\n",
      "Saved 207 slice 1\n",
      "Saved 207 slice 2\n",
      "Saved 207 slice 3\n",
      "Saved 207 slice 4\n",
      "Saved 207 slice 5\n",
      "Saved 207 slice 6\n",
      "Saved 207 slice 7\n",
      "Saved 207 slice 8\n",
      "Saved 207 slice 9\n",
      "Saved 229 slice 0\n",
      "Saved 229 slice 1\n",
      "Saved 229 slice 2\n",
      "Saved 229 slice 3\n",
      "Saved 229 slice 4\n",
      "Saved 229 slice 5\n",
      "Saved 229 slice 6\n",
      "Saved 229 slice 7\n",
      "Saved 229 slice 8\n",
      "Saved 304 slice 0\n",
      "Saved 304 slice 1\n",
      "Saved 304 slice 2\n",
      "Saved 304 slice 3\n",
      "Saved 304 slice 4\n",
      "Saved 304 slice 5\n",
      "Saved 304 slice 6\n",
      "Saved 304 slice 7\n",
      "Saved 304 slice 8\n",
      "Saved 11 slice 0\n",
      "Saved 11 slice 1\n",
      "Saved 11 slice 2\n",
      "Saved 11 slice 3\n",
      "Saved 11 slice 4\n",
      "Saved 11 slice 5\n",
      "Saved 11 slice 6\n",
      "Saved 11 slice 7\n",
      "Saved 11 slice 8\n",
      "Saved 173 slice 0\n",
      "Saved 173 slice 1\n",
      "Saved 173 slice 2\n",
      "Saved 173 slice 3\n",
      "Saved 173 slice 4\n",
      "Saved 173 slice 5\n",
      "Saved 173 slice 6\n",
      "Saved 190 slice 0\n",
      "Saved 190 slice 1\n",
      "Saved 190 slice 2\n",
      "Saved 190 slice 3\n",
      "Saved 190 slice 4\n",
      "Saved 190 slice 5\n",
      "Saved 190 slice 6\n",
      "Saved 190 slice 7\n",
      "Saved 198 slice 0\n",
      "Saved 198 slice 1\n",
      "Saved 198 slice 2\n",
      "Saved 198 slice 3\n",
      "Saved 198 slice 4\n",
      "Saved 198 slice 5\n",
      "Saved 198 slice 6\n",
      "Saved 198 slice 7\n",
      "Saved 202 slice 0\n",
      "Saved 202 slice 1\n",
      "Saved 202 slice 2\n",
      "Saved 202 slice 3\n",
      "Saved 202 slice 4\n",
      "Saved 202 slice 5\n",
      "Saved 202 slice 6\n",
      "Saved 202 slice 7\n",
      "Saved 202 slice 8\n",
      "Saved 204 slice 0\n",
      "Saved 204 slice 1\n",
      "Saved 204 slice 2\n",
      "Saved 204 slice 3\n",
      "Saved 204 slice 4\n",
      "Saved 204 slice 5\n",
      "Saved 218 slice 0\n",
      "Saved 218 slice 1\n",
      "Saved 218 slice 2\n",
      "Saved 218 slice 3\n",
      "Saved 218 slice 4\n",
      "Saved 218 slice 5\n"
     ]
    }
   ],
   "source": [
    "# This would be main in .py\n",
    "\n",
    "# read in csv split on folders y/n\n",
    "csv_file = \"ED_slices_and_timepoints.csv\" #For the future, once we structure our folders/files better we need to (probably) adjust this import\n",
    "df = pd.read_csv(csv_file)\n",
    "#display(df)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "df[\"Folders (y/n)\"] = df[\"Folders (y/n)\"].str.strip().str.lower()\n",
    "\n",
    "df_y = df[df[\"Folders (y/n)\"] == 'y'].reset_index(drop=True)\n",
    "df_n = df[df[\"Folders (y/n)\"] == 'n'].reset_index(drop=True)\n",
    "\n",
    "#display(df_n)\n",
    "#display(df_y)\n",
    "\n",
    "# Change this based on where you store the data\n",
    "# base_path = \"/Users/au698484/Documents/SSCP25_data/Data and scripts SSCP25 3/CMR_image_data/new data-dicom\"\n",
    "base_path = '/Users/inad001/Documents/SSCP25/Data and scripts SSCP25/CMR_image_data/new data-dicom'\n",
    "\n",
    "files_n = get_relevant_files_n(df_n, base_path)\n",
    "files_y = get_relevant_files_y(df_y, base_path)\n",
    "\n",
    "# Call segmentation and save segmentations and images under specified output file (change to match your own destination)\n",
    "# run_segmentation([files_n, files_y], output_root=\"/Users/au698484/Documents/SSCP25_data_segmented\")\n",
    "run_segmentation([files_n, files_y], output_root=\"/Users/inad001/Documents/SSCP25/segmented_data\", save_as_stack=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41a0e40",
   "metadata": {},
   "source": [
    "### ED_segmentation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7e3cab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.abspath(\"/Users/inad001/Documents/SSCP25/Data and scripts SSCP25/ED_segmentation_data/segmentation_stacks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "92ac66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmr_nifti_files(base_path):\n",
    "\n",
    "    patient_files = {}\n",
    "\n",
    "    for patient in os.listdir(base_path):\n",
    "        pid = patient.strip()\n",
    "\n",
    "        patient_path = os.path.join(base_path, pid)\n",
    "\n",
    "        if not os.path.isdir(patient_path):\n",
    "            print(f\"Warning: {patient_path} is not a directory\")\n",
    "            continue\n",
    "\n",
    "        files = [os.path.join(patient_path, f) for f in os.listdir(patient_path) if f.startswith(\"cmr\") and f.endswith(\".nii\")]\n",
    "\n",
    "        if not files:\n",
    "            print(f\"Warning: no valid files found for patient {pid}\")\n",
    "            continue\n",
    "\n",
    "        patient_files[pid] = files\n",
    "    \n",
    "    return patient_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2d8051de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_segmentation_nifti(files_dicts, output_root, save_as_stack: bool):\n",
    "    \"\"\"\n",
    "    Runs MONAI ventricular segmentation on all DICOM files provided in files_dicts.\n",
    "\n",
    "    Parameters:\n",
    "        files_dicts (list[dict]): List of dicts (e.g., [files_n, files_y]) with {pid: [file_paths]}.\n",
    "        output_root (str): Root folder where output NIfTI files will be saved.\n",
    "    \"\"\"\n",
    "    # Load MONAI network config & weights\n",
    "    parser = load_bundle_config(\"MONAI\", \"train.json\")\n",
    "    net = parser.get_parsed_content(\"network_def\")\n",
    "\n",
    "    model_path = hf_hub_download(\n",
    "        repo_id=\"MONAI/ventricular_short_axis_3label\",\n",
    "        filename=\"models/model.pt\"\n",
    "    )\n",
    "    net.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    net.eval()\n",
    "\n",
    "    target_shape = (256, 256) \n",
    "\n",
    "    for files_dict in files_dicts:\n",
    "        for pid, paths in files_dict.items():\n",
    "            # Read and preprocess NIfTI file\n",
    "            img_stack = np.array(nib.load(paths[0]).get_fdata().astype(np.float32))\n",
    "            \n",
    "            num_slices = img_stack.shape[2]\n",
    "            processed_img_stack = []\n",
    "            seg_stack = []\n",
    "\n",
    "            for idx in range(img_stack.shape[2]):\n",
    "                img = img_stack[:, :, idx]  # Get the current slice\n",
    "                #print(f\"Original image shape: {img.shape}, ndim: {img.ndim}\")\n",
    "\n",
    "                # Resample width and height to fixed size (256, 256) \n",
    "                im_resized = cv2.resize(img, (target_shape[1], target_shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # Adjust contrast\n",
    "                # img = cv2.convertScaleAbs(img, alpha=1.465, beta=0.0) # Used alpha-value provided by Giulia (this adjusts contrast)\n",
    "\n",
    "                #print(f\"Resized image shape: {im_resized.shape}\")\n",
    "\n",
    "                # Normalize and add batch & channel dims\n",
    "                # input_tensor = torch.from_numpy(im_resized / im_resized.max()).float()[None, None, :, :]\n",
    "                # Normalize and add batch & channel dims\n",
    "                im_resized = np.clip(im_resized, 0, np.percentile(im_resized, 99.5))\n",
    "                normed_im = im_resized / (np.max(im_resized) + 1e-5)\n",
    "                # normed_im = cv2.convertScaleAbs(normed_im, alpha=0.8, beta=0.0) # Used alpha-value provided by Giulia (this adjusts contrast)\n",
    "                # normed_im = im_resized # / im_resized.max()\n",
    "                alpha = 1.1  # small contrast adjustment\n",
    "                beta = 0.0\n",
    "\n",
    "                normed_im = np.clip(alpha * normed_im + beta, 0, 1.0)\n",
    "                input_tensor = torch.from_numpy(normed_im).float()[None, None, :, :]\n",
    "\n",
    "                # Predict\n",
    "                with torch.no_grad():\n",
    "                    pred = net(input_tensor)\n",
    "                    pred = torch.softmax(pred[0], dim=0)\n",
    "                    seg = torch.argmax(pred, dim=0).numpy()\n",
    "\n",
    "                if save_as_stack:\n",
    "                    processed_img_stack.append(normed_im)\n",
    "                    seg_stack.append(seg)\n",
    "                else:\n",
    "                    # Save\n",
    "                    pid_folder = os.path.join(output_root, str(pid))\n",
    "                    os.makedirs(pid_folder, exist_ok=True)\n",
    "\n",
    "                    affine = np.eye(4)  # identity affine \n",
    "                    #TODO: Look into this. This is an identity affine to map from numpy array to nifti file format, but we should probably\n",
    "                    # use the one from the DICOM - or does this not matter for input into Giulia's code?\n",
    "\n",
    "                    nib.save(nib.Nifti1Image(normed_im, affine), os.path.join(pid_folder, f\"{idx}_img.nii.gz\"))\n",
    "                    nib.save(nib.Nifti1Image(seg.astype(np.uint8), affine), os.path.join(pid_folder, f\"{idx}_seg.nii.gz\"))\n",
    "\n",
    "                    print(f\"Saved {pid} slice {idx}\")\n",
    "        \n",
    "            if save_as_stack and num_slices > 0: # NOTE: The order of the slices for patients with no folder structure is not necessarily correct.\n",
    "                \n",
    "                # Save the entire stack as a single NIfTI file\n",
    "                pid_folder = os.path.join(output_root, str(pid))\n",
    "                os.makedirs(pid_folder, exist_ok=True)\n",
    "\n",
    "                processed_img_stack = np.stack(processed_img_stack, axis=-1)\n",
    "                seg_stack = np.stack(seg_stack, axis=-1)\n",
    "\n",
    "                affine = np.eye(4)  # identity affine for the stack\n",
    "\n",
    "                nib.save(nib.Nifti1Image(processed_img_stack, affine), os.path.join(pid_folder, \"img_stack.nii.gz\"))\n",
    "                nib.save(nib.Nifti1Image(seg_stack.astype(np.uint8), affine), os.path.join(pid_folder, \"seg_stack.nii.gz\"))\n",
    "\n",
    "                print(f\"Saved {pid} image and segmentation stacks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "72fc2166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /Users/inad001/Documents/SSCP25/Data and scripts SSCP25/ED_segmentation_data/segmentation_stacks/.DS_Store is not a directory\n"
     ]
    }
   ],
   "source": [
    "cmr_files = get_cmr_nifti_files(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "44b97738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 95 image and segmentation stacks\n",
      "Saved 132 image and segmentation stacks\n",
      "Saved 92 image and segmentation stacks\n",
      "Saved 66 image and segmentation stacks\n",
      "Saved 103 image and segmentation stacks\n",
      "Saved 157 image and segmentation stacks\n",
      "Saved 150 image and segmentation stacks\n",
      "Saved 166 image and segmentation stacks\n",
      "Saved 35 image and segmentation stacks\n",
      "Saved 161 image and segmentation stacks\n",
      "Saved 102 image and segmentation stacks\n",
      "Saved 105 image and segmentation stacks\n",
      "Saved 58 image and segmentation stacks\n",
      "Saved 67 image and segmentation stacks\n",
      "Saved 93 image and segmentation stacks\n",
      "Saved 94 image and segmentation stacks\n",
      "Saved 160 image and segmentation stacks\n",
      "Saved 158 image and segmentation stacks\n",
      "Saved 167 image and segmentation stacks\n",
      "Saved 151 image and segmentation stacks\n",
      "Saved 169 image and segmentation stacks\n",
      "Saved 180 image and segmentation stacks\n",
      "Saved 187 image and segmentation stacks\n",
      "Saved 27 image and segmentation stacks\n",
      "Saved 145 image and segmentation stacks\n",
      "Saved 142 image and segmentation stacks\n",
      "Saved 129 image and segmentation stacks\n",
      "Saved 73 image and segmentation stacks\n",
      "Saved 118 image and segmentation stacks\n",
      "Saved 127 image and segmentation stacks\n",
      "Saved 120 image and segmentation stacks\n",
      "Saved 17 image and segmentation stacks\n",
      "Saved 188 image and segmentation stacks\n",
      "Saved 144 image and segmentation stacks\n",
      "Saved 1 image and segmentation stacks\n",
      "Saved 8 image and segmentation stacks\n",
      "Saved 181 image and segmentation stacks\n",
      "Saved 175 image and segmentation stacks\n",
      "Saved 21 image and segmentation stacks\n",
      "Saved 75 image and segmentation stacks\n",
      "Saved 121 image and segmentation stacks\n",
      "Saved 126 image and segmentation stacks\n",
      "Saved 162 image and segmentation stacks\n",
      "Saved 31 image and segmentation stacks\n",
      "Saved 91 image and segmentation stacks\n",
      "Saved 65 image and segmentation stacks\n",
      "Saved 62 image and segmentation stacks\n",
      "Saved 96 image and segmentation stacks\n",
      "Saved 109 image and segmentation stacks\n",
      "Saved 54 image and segmentation stacks\n",
      "Saved 107 image and segmentation stacks\n",
      "Saved 138 image and segmentation stacks\n",
      "Saved 53 image and segmentation stacks\n",
      "Saved 164 image and segmentation stacks\n",
      "Saved 163 image and segmentation stacks\n",
      "Saved 39 image and segmentation stacks\n",
      "Saved 152 image and segmentation stacks\n",
      "Saved 106 image and segmentation stacks\n",
      "Saved 139 image and segmentation stacks\n",
      "Saved 137 image and segmentation stacks\n",
      "Saved 97 image and segmentation stacks\n",
      "Saved 108 image and segmentation stacks\n",
      "Saved 63 image and segmentation stacks\n",
      "Saved 130 image and segmentation stacks\n",
      "Saved 112 image and segmentation stacks\n",
      "Saved 123 image and segmentation stacks\n",
      "Saved 70 image and segmentation stacks\n",
      "Saved 84 image and segmentation stacks\n",
      "Saved 170 image and segmentation stacks\n",
      "Saved 141 image and segmentation stacks\n",
      "Saved 4 image and segmentation stacks\n",
      "Saved 3 image and segmentation stacks\n",
      "Saved 146 image and segmentation stacks\n",
      "Saved 12 image and segmentation stacks\n",
      "Saved 76 image and segmentation stacks\n",
      "Saved 114 image and segmentation stacks\n",
      "Saved 78 image and segmentation stacks\n",
      "Saved 178 image and segmentation stacks\n",
      "Saved 182 image and segmentation stacks\n",
      "Saved 176 image and segmentation stacks\n",
      "Saved 149 image and segmentation stacks\n",
      "Saved 171 image and segmentation stacks\n"
     ]
    }
   ],
   "source": [
    "# Run segmentation on the CMR files\n",
    "run_segmentation_nifti([cmr_files], output_root=\"/Users/inad001/Documents/SSCP25/segmented_nifti\", save_as_stack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0dd7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
